{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron model\n",
    "\n",
    "Features extracted:\n",
    "- Window feature\n",
    "- Suffix feature\n",
    "- Shape feature\n",
    "- distributional feature (not used)\n",
    "\n",
    "Best performance: accuracy **95.65%** on corpus $fr.ftb$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data sets and choose one as our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_ftb = json.load(open('./corpus/fr/fr.ftb.train.json', encoding = 'utf-8'))\n",
    "test_set_ftb = json.load(open('./corpus/fr/fr.ftb.test.json', encoding = 'utf-8'))\n",
    "train_set_gsd = json.load(open('./corpus/fr/fr.gsd.train.json', encoding = 'utf-8'))\n",
    "test_set_gsd = json.load(open('./corpus/fr/fr.gsd.test.json', encoding = 'utf-8'))\n",
    "train_set_partut = json.load(open('./corpus/fr/fr.partut.train.json', encoding = 'utf-8'))\n",
    "test_set_partut = json.load(open('./corpus/fr/fr.partut.test.json', encoding = 'utf-8'))\n",
    "train_set_pud = json.load(open('./corpus/fr/fr.pud.train.json', encoding = 'utf-8'))\n",
    "test_set_pud = json.load(open('./corpus/fr/fr.pud.test.json', encoding = 'utf-8'))\n",
    "train_set_sequoia = json.load(open('./corpus/fr/fr.sequoia.train.json', encoding = 'utf-8'))\n",
    "test_set_sequoia = json.load(open('./corpus/fr/fr.sequoia.test.json', encoding = 'utf-8'))\n",
    "train_set_spoken = json.load(open('./corpus/fr/fr.spoken.train.json', encoding = 'utf-8'))\n",
    "test_set_spoken = json.load(open('./corpus/fr/fr.spoken.test.json', encoding = 'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set_ftb\n",
    "test_set = test_set_ftb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pick_out_punct**: Before extracting the features, we first pick out the PUNCT from the train set. When predicting, if the model meet a punct which is already recorded in the list of puncts, then it can give the right result without ''thinking''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_out_punct(data_set):\n",
    "    \n",
    "    punct = set()\n",
    "    \n",
    "    for sentence,labels in data_set:\n",
    "        for word,label in zip(sentence,labels):\n",
    "            if label == 'PUNCT':\n",
    "                punct.add(word)\n",
    "    \n",
    "    return punct\n",
    "     \n",
    "puncts = pick_out_punct(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**feature_window**: Return a list of the window features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_window(i, sentence, l=2):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    word = sentence[i]\n",
    "    res.append(word)\n",
    "    \n",
    "    for k in range(1,l+1):\n",
    "        \n",
    "        res.append('win_-'+str(k)+'_'+(sentence[i-k] if i-k>=0 else 'none'))\n",
    "        res.append('win_+'+str(k)+'_'+(sentence[i+k] if i+k<len(sentence) else 'none'))\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**feature_suffix**: Return a list of the suffix features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_suffix(i,sentence):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for k in range(1,len(sentence[i])):\n",
    "        res.append('suffix_'+sentence[i][k:])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**feature_shape**: Return a list of the shape features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_shape(i, sentence):\n",
    "\n",
    "    def has_digit(s):\n",
    "\n",
    "        return any(c.isdigit() for c in s)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    word = sentence[i]\n",
    "    \n",
    "    if word.istitle():\n",
    "        res.append('start_capital')\n",
    "    if word.isupper():\n",
    "        res.append('all_capital')\n",
    "    if has_digit(word):\n",
    "        res.append('has_digit')\n",
    "    if '-' in word:\n",
    "        res.append('has_hyphen')\n",
    "    if '_' in word:\n",
    "        res.append('has_hyphen_low')\n",
    "    if not word.isalnum():\n",
    "        res.append('not_alnum')\n",
    "    if len(word) > 3:\n",
    "         res.append('word_len_>_3')\n",
    "    if '\\'' in word:\n",
    "        res.append('abbr')\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**get_bigram**: Extract the bigram from both side of a word and construct two dictionary to stock the times that a bigram appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigram(data_set):\n",
    "    \n",
    "    bigram_left = defaultdict(lambda: defaultdict(int))\n",
    "    bigram_right = defaultdict(lambda: defaultdict(int))\n",
    "    for sentence,labels in data_set:\n",
    "        for i in range(1,len(sentence)):\n",
    "            bigram_left[sentence[i]][sentence[i-1]] += 1\n",
    "            bigram_right[sentence[i-1]][sentence[i]] += 1\n",
    "            \n",
    "            \n",
    "    return bigram_left,bigram_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**feature_distributional**: Sort the dictionary of bigram to extract the distributional features (very time cosuming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_distributional(i,sentence,bigram,direction):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    word = sentence[i]\n",
    "    \n",
    "    bigram_words = bigram[word]\n",
    "\n",
    "    m = sorted(bigram_words.items(), key = lambda item: item[1])\n",
    "    \n",
    "    freq_level = 0\n",
    "    \n",
    "    for k in m:\n",
    "        freq_level += 1\n",
    "        res.append(str(freq_level)+'_freq_'+k[0])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**collect_features_and_labels**: The 'main' function for extracting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_features_and_labels(data_set):\n",
    "    \n",
    "    data = []\n",
    "    label = []\n",
    "    \n",
    "    punct = pick_out_punct(data_set)\n",
    "    \n",
    "    bigram_left,bigram_right = get_bigram(data_set)\n",
    "    \n",
    "    for sentence,labels in data_set:\n",
    "        \n",
    "        for i in range(len(sentence)):\n",
    "            \n",
    "            if sentence[i] in punct:\n",
    "                data.append(list(sentence[i]))\n",
    "            \n",
    "            else:\n",
    "                data_of_word = []\n",
    "\n",
    "                data_of_word += feature_window(i, sentence)\n",
    "                data_of_word += feature_suffix(i, sentence)\n",
    "                data_of_word += feature_shape(i, sentence)\n",
    "                #data_of_word += feature_distributional(i, sentence, bigram_left,'_left_')\n",
    "\n",
    "                data.append(data_of_word)\n",
    "        \n",
    "        label += labels\n",
    "            \n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**oov_features_and_labels**: Construct the data set for the OOV words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oov_features_and_labels(train_data,test_data,test_label):\n",
    "    \n",
    "    words = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for word in train_data:\n",
    "        words.append(word[0])\n",
    "    \n",
    "    train_words = set(words)\n",
    "    \n",
    "    for word,label in zip(test_data,test_label):\n",
    "        if word[0] not in train_words:\n",
    "            data.append(word)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ambiguous_features_and_labels**: Construct the data set for the ambiguous words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ambiguous_features_and_labels(input_data,input_label):\n",
    "    \n",
    "    words = defaultdict(lambda: set())\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for word,label in zip(input_data,input_label):\n",
    "        words[word[0]].add(label)\n",
    "    \n",
    "    for word,label in zip(input_data,input_label):\n",
    "        if(len(words[word[0]]) > 1):\n",
    "            data.append(word)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return data,labels\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the Perceptron model:\n",
    "- **key parameters**: labels, weights, weights_average (which is mentioned as $r$ in the report).\n",
    "- **fit**: Iterate $epochs$ times over all the train set and call the update function to update the weights.\n",
    "- **update_predict**: which is only used for training step, consider all the features of an input value to predict the label.\n",
    "- **predict**: which is used for testing step, simply return punct when seeing an input which is a recorded punct. (This can slightly increase the performance)\n",
    "- **predict_all**: predict all the words from a data set.\n",
    "- **update**: update weights & weights_averages\n",
    "- **evaluate**: calculate the accuracy of a result.\n",
    "- **sigmoid & relu**: activation functions, used in **predict**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_perceptron:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.labels = []\n",
    "        \n",
    "        self.weights = defaultdict(lambda: defaultdict(float))\n",
    "        \n",
    "        self.weights_average = defaultdict(lambda: defaultdict(float))\n",
    "        \n",
    "    def fit(self,sentences,labels,epochs):\n",
    "        \n",
    "        self.labels = list(set(labels))\n",
    "        \n",
    "        for _ in range(epochs):\n",
    "            \n",
    "            for features,label in zip(sentences,labels):\n",
    "\n",
    "                self.update(features,label)\n",
    "            \n",
    "            \n",
    "     \n",
    "    def update_predict(self,features):\n",
    "        \n",
    "        label_volt = np.zeros(len(self.labels))\n",
    "        \n",
    "        for feature in features:\n",
    "            \n",
    "            for label in self.labels:\n",
    "                \n",
    "                label_volt[self.labels.index(label)] += self.sigmoid(self.weights[feature][label])\n",
    "         \n",
    "        label_predict = self.labels[np.argmax(label_volt)]\n",
    "        \n",
    "        return label_predict\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self,features):\n",
    "        \n",
    "        if features[0] in puncts:\n",
    "            \n",
    "            return 'PUNCT'\n",
    "        \n",
    "        label_volt = np.zeros(len(self.labels))\n",
    "        \n",
    "        for feature in features:\n",
    "            \n",
    "            for label in self.labels:\n",
    "                \n",
    "                label_volt[self.labels.index(label)] += self.sigmoid(self.weights[feature][label])\n",
    "         \n",
    "        label_predict = self.labels[np.argmax(label_volt)]\n",
    "        \n",
    "        return label_predict\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict_all(self,sentences):\n",
    "        \n",
    "        labels_predict = []\n",
    "        \n",
    "        for features in sentences:\n",
    "            \n",
    "            labels_predict.append(self.predict(features))\n",
    "            \n",
    "        return labels_predict\n",
    "    \n",
    "    \n",
    "    \n",
    "    def evaluate(self,sentences,labels):\n",
    "        \n",
    "        labels_predict = self.predict_all(sentences)\n",
    "        \n",
    "        correct_num = 0.\n",
    "        \n",
    "        for label_predict,label_real in zip(labels_predict,labels):\n",
    "            if label_predict == label_real:\n",
    "                correct_num += 1.\n",
    "        \n",
    "        return correct_num/len(labels) * 100\n",
    "    \n",
    "    \n",
    "    \n",
    "    def update(self,features,label_real):\n",
    "        \n",
    "        label_predict = self.update_predict(features)\n",
    "        delta = 10**(-7)\n",
    "            \n",
    "        if (label_predict == label_real):\n",
    "            return \n",
    "        \n",
    "        for feature in features:\n",
    "            \n",
    "            self.weights_average[feature][label_predict] += np.log(0.9)**2\n",
    "            self.weights_average[feature][label_real] += np.log(1.1)**2\n",
    "            \n",
    "            self.weights[feature][label_predict] += np.log(0.9)/(delta+np.sqrt(self.weights_average[feature][label_predict]))\n",
    "            \n",
    "            self.weights[feature][label_real] += np.log(1.1)/(delta+np.sqrt(self.weights_average[feature][label_real]))\n",
    "            #print(self.weights[feature][label_real])\n",
    "    \n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        \n",
    "        z = 1/(1 + np.exp(-x))\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    \n",
    "    def relu(self,x):\n",
    "        \n",
    "        z = max(0,x)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all the features from train set and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time =  3.1652774810791016\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "train_data,train_label = collect_features_and_labels(train_set)\n",
    "end = time.time()\n",
    "print('total time = ',end - begin)\n",
    "\n",
    "test_data,test_label = collect_features_and_labels(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['La', 'win_-1_none', 'win_+1_limite', 'win_-2_none', 'win_+2_des', 'suffix_a', 'start_capital']\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the **OOV** set and the **Ambuguous** set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov_data,oov_label = oov_features_and_labels(train_data,test_data,test_label)\n",
    "ambiguous_data,ambiguous_label = ambiguous_features_and_labels(train_data,train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize, train, evaluate the Perceptron model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = simple_perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.fit(train_data,train_label,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test = p.evaluate(test_data,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "oov = p.evaluate(oov_data,oov_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "amb = p.evaluate(ambiguous_data,ambiguous_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 95.36184780147323\n",
      "oov accuracy: 80.41930379746836\n",
      "amb accuracy: 97.91951575989135\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy:',all_test)\n",
    "print('oov accuracy:',oov)\n",
    "print('amb accuracy:',amb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the two other corpus $fr.foot$ & $fr.natdis$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "foot_test_set = json.load(open('./corpus/fr/fr.foot.test.json', encoding = 'utf-8'))\n",
    "foot_test_data,foot_test_label = collect_features_and_labels(foot_test_set)\n",
    "foot_oov_data,foot_oov_label = oov_features_and_labels(train_data,foot_test_data,foot_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of simple perceptron model: 69.0525563103325%\n",
      "accuracy of simple perceptron model: 33.752129471890974%\n"
     ]
    }
   ],
   "source": [
    "all_test_foot = p.evaluate(foot_test_data,foot_test_label)\n",
    "oov_foot = p.evaluate(foot_oov_data,foot_oov_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test accuracy:',all_test_foot)\n",
    "print('oov accuracy:',oov_foot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_test_set = json.load(open('./corpus/fr/fr.natdis.test.json', encoding = 'utf-8'))\n",
    "nat_test_data,nat_test_label = collect_features_and_labels(nat_test_set)\n",
    "nat_oov_data,nat_oov_label = oov_features_and_labels(train_data,nat_test_data,nat_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of simple perceptron model: 78.24642975755563%\n",
      "accuracy of simple perceptron model: 26.174496644295303%\n"
     ]
    }
   ],
   "source": [
    "all_test_natdis = p.evaluate(nat_test_data,nat_test_label)\n",
    "amb_natdis = p.evaluate(nat_oov_data,nat_oov_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test accuracy:',all_test_natdis)\n",
    "print('oov accuracy:',oov_natdis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
